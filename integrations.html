<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>API Integrations - Airtable Lead Enricher</title>
    <link rel="icon" type="image/png" href="https://images.apifyusercontent.com/hIWSIagcj8949hoLcWRj_q-7YXhT9xpVuYWR4RP93uU/rs:fill:250:250/cb:1/aHR0cHM6Ly9hcGlmeS1pbWFnZS11cGxvYWRzLXByb2QuczMudXMtZWFzdC0xLmFtYXpvbmF3cy5jb20vOHp1MThIQW4xN1Q4NXpGeFUtYWN0b3ItY1ZEcEF0dHBoY3BETTR2RngtMnpveEVnMEhlRi1haXJ0YWJsZS1sZWFkLWVucmljaGVyLXRyYW5zcGFyZW50LnBuZw.webp">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }

        .doc-layout {
            display: flex;
            min-height: 100vh;
        }

        /* Sidebar TOC */
        .sidebar {
            width: 280px;
            background: white;
            border-right: 1px solid #e0e0e0;
            position: fixed;
            height: 100vh;
            overflow-y: auto;
            padding: 20px;
        }

        .sidebar-header {
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 2px solid #667eea;
        }

        .sidebar-header h2 {
            color: #667eea;
            font-size: 1.3em;
            margin-bottom: 5px;
        }

        .sidebar-header .version {
            color: #666;
            font-size: 0.85em;
        }

        .toc {
            list-style: none;
        }

        .toc li {
            margin-bottom: 5px;
        }

        .toc a {
            color: #333;
            text-decoration: none;
            display: block;
            padding: 8px 12px;
            border-radius: 4px;
            font-size: 0.95em;
            transition: all 0.2s;
        }

        .toc a:hover {
            background: #f0f0f0;
            color: #667eea;
        }

        .toc a.active {
            background: #667eea;
            color: white;
        }

        .toc .toc-subsection {
            list-style: none;
            margin-left: 15px;
            margin-top: 5px;
        }

        .toc .toc-subsection a {
            font-size: 0.85em;
            padding: 6px 10px;
        }

        .back-link {
            display: block;
            margin-bottom: 15px;
            color: #667eea;
            font-weight: 500;
            font-size: 0.9em;
        }

        /* Main content */
        .main-content {
            margin-left: 280px;
            flex: 1;
            padding: 40px 60px;
            max-width: 1200px;
        }

        .content-wrapper {
            background: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }

        h1 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 2.5em;
        }

        .version-tag {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 30px;
            display: inline-block;
            padding: 5px 15px;
            background: #f0f0f0;
            border-radius: 20px;
        }

        h2 {
            color: #764ba2;
            margin-top: 50px;
            margin-bottom: 20px;
            font-size: 1.8em;
            border-bottom: 2px solid #f0f0f0;
            padding-bottom: 10px;
            padding-top: 20px;
        }

        h2:first-of-type {
            margin-top: 30px;
        }

        h3 {
            color: #667eea;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        p {
            margin-bottom: 15px;
            line-height: 1.8;
        }

        ul, ol {
            margin-bottom: 15px;
            margin-left: 25px;
        }

        li {
            margin-bottom: 8px;
            line-height: 1.6;
        }

        a {
            color: #667eea;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        strong {
            color: #333;
        }

        .info-box {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
        }

        .warning-box {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
        }

        .success-box {
            background: #d4edda;
            border-left: 4px solid #28a745;
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
        }

        code {
            background: #f5f5f5;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }

        pre {
            background: #282c34;
            border-radius: 4px;
            overflow-x: auto;
            margin: 1rem 0;
        }

        pre code {
            background: transparent;
            padding: 0;
            display: block;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }

        th, td {
            padding: 0.75rem;
            text-align: left;
            border-bottom: 1px solid #e2e8f0;
        }

        th {
            background: #f7fafc;
            font-weight: 600;
            color: #667eea;
        }

        tr:hover {
            background: #f9f9f9;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .sidebar {
                display: none;
            }

            .main-content {
                margin-left: 0;
                padding: 20px;
            }

            .content-wrapper {
                padding: 20px;
            }

            h1 {
                font-size: 2em;
            }

            h2 {
                font-size: 1.5em;
            }
        }
    </style>
</head>
<body>
    <div class="doc-layout">
        <!-- Left Sidebar TOC -->
        <aside class="sidebar">
            <a href="index.html" class="back-link">‚Üê Documentation</a>

            <div class="sidebar-header">
                <h2>API Integrations</h2>
                <span class="version">API Mode</span>
            </div>

            <nav>
                <ul class="toc">
                    <li><a href="#overview">API Mode Overview</a></li>
                    <li><a href="#self-hosted">Self-Hosted Deployment</a></li>
                    <li><a href="#configuration">Configuration Options</a></li>
                    <li><a href="#python">Python Example</a></li>
                    <li><a href="#nodejs">Node.js Example</a></li>
                    <li><a href="#bedrock">AWS Bedrock Example</a></li>
                    <li><a href="#output-schema">Output Schema</a></li>
                    <li><a href="#webhook">Webhook Integration</a></li>
                    <li><a href="#lambda">AWS Lambda</a></li>
                    <li><a href="#airflow">Apache Airflow</a></li>
                    <li><a href="#glue">AWS Glue</a></li>
                    <li><a href="#gcp">Google Cloud Functions</a></li>
                    <li><a href="#step-functions">AWS Step Functions</a></li>
                    <li><a href="#snowflake">Snowflake</a></li>
                    <li><a href="#redshift">Amazon Redshift</a></li>
                    <li><a href="#data-lake">Data Lake Pattern</a></li>
                    <li><a href="#rate-limits">Rate Limits & Batching</a></li>
                    <li><a href="#cost-estimation">Cost Estimation</a></li>
                </ul>
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <div class="content-wrapper">
                <h1 id="overview">API Integrations</h1>
                <span class="version-tag">Use without Airtable via API mode</span>

                <p>The Airtable Lead Enricher can be used as a standalone API service without requiring an Airtable base. This enables integration with any data pipeline, workflow automation, or business intelligence tool.</p>

                <h2 id="overview">API Mode Overview</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Feature</th>
                            <th>Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Max companies/run</td>
                            <td>100</td>
                        </tr>
                        <tr>
                            <td>Input</td>
                            <td>JSON array</td>
                        </tr>
                        <tr>
                            <td>Output</td>
                            <td>Dataset + Webhook</td>
                        </tr>
                        <tr>
                            <td>Airtable required</td>
                            <td>No</td>
                        </tr>
                    </tbody>
                </table>

                <h2 id="self-hosted">üè¢ Self-Hosted Deployment</h2>

                <p>For teams processing high volumes or needing data to stay on-premise, we offer a fully self-hosted deployment option.</p>

                <div class="success-box">
                    <strong>üéØ Enterprise Solution:</strong> Get complete control over your lead enrichment infrastructure with deployment to your own AWS Lambda or container environment.
                </div>

                <h3>What You Get</h3>
                <ul>
                    <li><strong>Full Deployment:</strong> Complete setup to your AWS Lambda or container environment (ECS, Kubernetes, etc.)</li>
                    <li><strong>Source Code License:</strong> Full access to the enrichment engine source code with commercial license</li>
                    <li><strong>Airtable Integration:</strong> Seamless integration with your existing Airtable workspace</li>
                    <li><strong>Setup Documentation:</strong> Comprehensive deployment guides and technical documentation</li>
                    <li><strong>Customization Support:</strong> Initial support for custom integrations and modifications</li>
                </ul>

                <h3>Best For</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Use Case</th>
                            <th>Why Self-Hosted?</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>High Volume Processing</strong></td>
                            <td>50,000+ leads per month with predictable costs</td>
                        </tr>
                        <tr>
                            <td><strong>Compliance Requirements</strong></td>
                            <td>HIPAA, SOC2, or internal data policies requiring on-premise processing</td>
                        </tr>
                        <tr>
                            <td><strong>Data Sovereignty</strong></td>
                            <td>Data must remain within specific geographic regions or cloud accounts</td>
                        </tr>
                        <tr>
                            <td><strong>Custom Integrations</strong></td>
                            <td>Need to modify enrichment logic or integrate proprietary data sources</td>
                        </tr>
                        <tr>
                            <td><strong>Cost Optimization</strong></td>
                            <td>At scale, self-hosted can be more cost-effective than per-lead pricing</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Architecture Options</h3>

                <h4>Option 1: AWS Lambda</h4>
                <ul>
                    <li>Serverless deployment with automatic scaling</li>
                    <li>Pay only for compute time used</li>
                    <li>Integrates with S3, DynamoDB, and other AWS services</li>
                    <li>Best for: Variable workloads, event-driven architectures</li>
                </ul>

                <h4>Option 2: Container Deployment (ECS/Kubernetes)</h4>
                <ul>
                    <li>Full control over compute resources</li>
                    <li>Supports complex enrichment workflows</li>
                    <li>Can run on AWS ECS, Google Kubernetes Engine, or on-premise clusters</li>
                    <li>Best for: Steady workloads, maximum customization</li>
                </ul>

                <h3>Pricing</h3>
                <p><strong style="font-size: 1.3rem; color: #667eea;">Starting at $1,000</strong></p>
                <p>One-time fee includes deployment, source code license, and initial setup support.</p>

                <div class="info-box">
                    <strong>üí∞ Cost Comparison:</strong> For teams processing 50,000+ leads/month, self-hosted deployment typically pays for itself within 2-3 months compared to per-lead pricing ($0.03/lead = $1,500/month for 50k leads).
                </div>

                <h3>Get Started</h3>
                <p>Contact us to discuss your requirements and deployment timeline:</p>
                <p><strong>üìß Email:</strong> <a href="mailto:contact@datahq.pro">contact@datahq.pro</a></p>
                <p>We'll schedule a consultation to:</p>
                <ul>
                    <li>Understand your volume and compliance requirements</li>
                    <li>Recommend the best architecture for your use case</li>
                    <li>Provide a detailed deployment plan and timeline</li>
                    <li>Answer any technical questions</li>
                </ul>

                <h2 id="configuration">Configuration Options</h2>
                <p>The API accepts a JSON payload with the following structure. All enrichment, LLM, and scoring options are optional and can be customized per your requirements.</p>

                <h3>Core Parameters</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Type</th>
                            <th>Required</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>mode</code></td>
                            <td>string</td>
                            <td>Yes</td>
                            <td>Must be <code>"api"</code> for API mode</td>
                        </tr>
                        <tr>
                            <td><code>companies</code></td>
                            <td>array</td>
                            <td>Yes</td>
                            <td>Array of company objects (max 100). Each object requires <code>companyName</code>, optional <code>website</code> and <code>location</code></td>
                        </tr>
                        <tr>
                            <td><code>webhookUrl</code></td>
                            <td>string</td>
                            <td>No</td>
                            <td>POST results to this URL when enrichment completes</td>
                        </tr>
                        <tr>
                            <td><code>enrichment</code></td>
                            <td>object</td>
                            <td>No</td>
                            <td>Enrichment configuration (sources, concurrency, timeouts)</td>
                        </tr>
                        <tr>
                            <td><code>scoring</code></td>
                            <td>object</td>
                            <td>No</td>
                            <td>Lead scoring configuration with ICP criteria</td>
                        </tr>
                        <tr>
                            <td><code>llm</code></td>
                            <td>object</td>
                            <td>No</td>
                            <td>AI/LLM provider configuration for enriched insights</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Enrichment Configuration</h3>
                <p>Control which data sources to use and how enrichment is performed:</p>

                <table>
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Type</th>
                            <th>Default</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>sources</code></td>
                            <td>array</td>
                            <td><code>["google_maps", "website"]</code></td>
                            <td>Data sources to use: <code>"google_maps"</code>, <code>"website"</code>, <code>"hunter"</code>, <code>"linkedin"</code>, <code>"facebook"</code>, <code>"twitter"</code></td>
                        </tr>
                        <tr>
                            <td><code>concurrency</code></td>
                            <td>number</td>
                            <td><code>10</code></td>
                            <td>Max parallel enrichments (1-10)</td>
                        </tr>
                        <tr>
                            <td><code>timeout</code></td>
                            <td>number</td>
                            <td><code>60</code></td>
                            <td>Per-company timeout in seconds</td>
                        </tr>
                        <tr>
                            <td><code>hunter</code></td>
                            <td>object</td>
                            <td><code>null</code></td>
                            <td>Hunter.io config: <code>{"enabled": true, "apiKey": "YOUR_KEY"}</code></td>
                        </tr>
                        <tr>
                            <td><code>googleMaps</code></td>
                            <td>object</td>
                            <td><code>{"enabled": true}</code></td>
                            <td>Google Maps config: <code>{"enabled": true, "includeReviews": false}</code></td>
                        </tr>
                        <tr>
                            <td><code>website</code></td>
                            <td>object</td>
                            <td><code>{"enabled": true}</code></td>
                            <td>Website scraping config: <code>{"enabled": true, "crawlDepth": 1, "timeout": 15}</code></td>
                        </tr>
                    </tbody>
                </table>

                <h3>LLM Configuration</h3>
                <p>Enable AI-powered enrichment for ICP scoring, summaries, and insights:</p>

                <table>
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Type</th>
                            <th>Default</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>enabled</code></td>
                            <td>boolean</td>
                            <td><code>false</code></td>
                            <td>Enable AI-powered enrichment</td>
                        </tr>
                        <tr>
                            <td><code>provider</code></td>
                            <td>string</td>
                            <td>-</td>
                            <td>LLM provider: <code>"anthropic"</code>, <code>"openai"</code>, or <code>"bedrock"</code></td>
                        </tr>
                        <tr>
                            <td><code>apiKey</code></td>
                            <td>string</td>
                            <td>-</td>
                            <td>API key for the provider (or Bedrock API key for new auth method)</td>
                        </tr>
                        <tr>
                            <td><code>model</code></td>
                            <td>string</td>
                            <td>Provider default</td>
                            <td>Model ID. Defaults: <code>"claude-3-5-haiku-20241022"</code> (Anthropic), <code>"gpt-4o-mini"</code> (OpenAI), <code>"us.anthropic.claude-haiku-4-5-20251001-v1:0"</code> (Bedrock)</td>
                        </tr>
                        <tr>
                            <td><code>temperature</code></td>
                            <td>number</td>
                            <td><code>0.3</code></td>
                            <td>Model temperature (0-1). Lower = more focused</td>
                        </tr>
                        <tr>
                            <td><code>maxTokens</code></td>
                            <td>number</td>
                            <td><code>1000</code></td>
                            <td>Maximum tokens per response</td>
                        </tr>
                        <tr>
                            <td><code>region</code></td>
                            <td>string</td>
                            <td><code>"us-east-1"</code></td>
                            <td><strong>Bedrock only:</strong> AWS region</td>
                        </tr>
                        <tr>
                            <td><code>awsAccessKeyId</code></td>
                            <td>string</td>
                            <td>-</td>
                            <td><strong>Bedrock only:</strong> AWS IAM Access Key (legacy auth method)</td>
                        </tr>
                        <tr>
                            <td><code>awsSecretAccessKey</code></td>
                            <td>string</td>
                            <td>-</td>
                            <td><strong>Bedrock only:</strong> AWS IAM Secret Key (legacy auth method)</td>
                        </tr>
                    </tbody>
                </table>

                <div class="info-box">
                    <strong>üÜï Bedrock Authentication:</strong> AWS Bedrock supports two authentication methods:
                    <ul style="margin-top: 10px; margin-bottom: 0;">
                        <li><strong>API Key (Recommended):</strong> Use <code>apiKey</code> with Bedrock API key</li>
                        <li><strong>IAM Credentials (Legacy):</strong> Use <code>awsAccessKeyId</code> + <code>awsSecretAccessKey</code></li>
                    </ul>
                </div>

                <h3>Scoring Configuration</h3>
                <p>Configure lead scoring with custom ICP criteria and weights:</p>

                <table>
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Type</th>
                            <th>Default</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>enabled</code></td>
                            <td>boolean</td>
                            <td><code>false</code></td>
                            <td>Enable lead scoring (requires LLM enabled)</td>
                        </tr>
                        <tr>
                            <td><code>icpCriteria</code></td>
                            <td>string</td>
                            <td>-</td>
                            <td>Your Ideal Customer Profile criteria (detailed text describing your target companies)</td>
                        </tr>
                        <tr>
                            <td><code>weights</code></td>
                            <td>object</td>
                            <td>See below</td>
                            <td>Scoring weights for different signals</td>
                        </tr>
                        <tr>
                            <td><code>minimumConfidence</code></td>
                            <td>number</td>
                            <td><code>0.3</code></td>
                            <td>Minimum data confidence threshold (0-1)</td>
                        </tr>
                    </tbody>
                </table>

                <h4>Default Scoring Weights</h4>
                <pre><code class="language-json">{
  "hasEmail": 20,      // 20 points if email found
  "hasPhone": 15,      // 15 points if phone found
  "socialPresence": 15, // 15 points for social profiles
  "reviewScore": 10,   // Up to 10 points based on ratings
  "icpMatch": 40       // Up to 40 points from AI ICP analysis
}</code></pre>

                <h3>Complete Configuration Example</h3>
                <pre><code class="language-json">{
  "mode": "api",
  "companies": [
    {
      "companyName": "Acme Corp",
      "website": "https://www.acmecorp.example",
      "location": "San Francisco, CA"
    }
  ],
  "webhookUrl": "https://your-system.example/webhook",
  "enrichment": {
    "sources": ["google_maps", "website", "hunter"],
    "concurrency": 10,
    "timeout": 60,
    "hunter": {
      "enabled": true,
      "apiKey": "YOUR_HUNTER_KEY"
    },
    "googleMaps": {
      "enabled": true,
      "includeReviews": false
    },
    "website": {
      "enabled": true,
      "crawlDepth": 1,
      "timeout": 15
    }
  },
  "llm": {
    "enabled": true,
    "provider": "bedrock",
    "apiKey": "YOUR_BEDROCK_API_KEY",
    "region": "us-east-1",
    "model": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
    "temperature": 0.3,
    "maxTokens": 1000
  },
  "scoring": {
    "enabled": true,
    "icpCriteria": "B2B SaaS companies with 50-500 employees, Series A+ funded, selling to enterprise customers, located in North America or Western Europe",
    "weights": {
      "hasEmail": 20,
      "hasPhone": 15,
      "socialPresence": 15,
      "reviewScore": 10,
      "icpMatch": 40
    },
    "minimumConfidence": 0.3
  }
}</code></pre>

                <h2 id="python">Python Example</h2>
                <p>Enrich leads using Python with both asynchronous and synchronous approaches:</p>

                <h3>Asynchronous (Recommended for Large Batches)</h3>
                <pre><code class="language-python">import requests
import time

APIFY_TOKEN = "your_token"

# Start run
run = requests.post(
    "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/runs",
    params={"token": APIFY_TOKEN},
    json={
        "mode": "api",
        "companies": [
            {"companyName": "Acme Corp", "website": "https://acme.com"}
        ],
        "enrichment": {
            "sources": ["google_maps", "website", "hunter"],
            "hunter": {
                "enabled": True,
                "apiKey": "YOUR_HUNTER_KEY"
            }
        },
        "llm": {
            "enabled": True,
            "provider": "openai",
            "apiKey": "YOUR_OPENAI_KEY"
        }
    }
).json()

# Wait for completion
run_id = run["data"]["id"]

while True:
    status = requests.get(
        f"https://api.apify.com/v2/actor-runs/{run_id}",
        params={"token": APIFY_TOKEN}
    ).json()

    if status["data"]["status"] in ["SUCCEEDED", "FAILED"]:
        break
    time.sleep(5)

# Get results
dataset_id = status["data"]["defaultDatasetId"]
results = requests.get(
    f"https://api.apify.com/v2/datasets/{dataset_id}/items",
    params={"token": APIFY_TOKEN}
).json()

print(results)</code></pre>

                <h3>Synchronous (Wait for Results)</h3>
                <pre><code class="language-python">response = requests.post(
    "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/run-sync-get-dataset-items",
    params={"token": APIFY_TOKEN},
    json={"mode": "api", "companies": [...]},
    timeout=300
)
results = response.json()</code></pre>

                <h2 id="nodejs">Node.js Example</h2>
                <p>Enrich leads using the Apify JavaScript client:</p>

                <pre><code class="language-javascript">const { ApifyClient } = require('apify-client');
const client = new ApifyClient({ token: 'your_token' });

async function enrichLeads(companies) {
    const run = await client.actor('datahq/airtable-lead-enricher').call({
        mode: 'api',
        companies: companies,
        enrichment: {
            sources: ['google_maps', 'website', 'hunter'],
            hunter: {
                enabled: true,
                apiKey: 'YOUR_HUNTER_KEY'
            }
        },
        llm: {
            enabled: true,
            provider: 'openai',
            apiKey: 'YOUR_OPENAI_KEY'
        }
    });

    const { items } = await client.dataset(run.defaultDatasetId).listItems();
    return items;
}

// Usage
const companies = [
    { companyName: 'Acme Corp', website: 'https://acme.com' }
];

enrichLeads(companies).then(results => {
    console.log(results);
});</code></pre>

                <h2 id="bedrock">AWS Bedrock Example (New!)</h2>
                <p>Use AWS Bedrock for cost-effective AI scoring with Claude models. Bedrock now supports simple API key authentication (no IAM credentials needed):</p>

                <div class="success-box">
                    <strong>üÜï Bedrock API Keys:</strong> As of July 2025, AWS Bedrock supports API key authentication! Generate a key in the <a href="https://console.aws.amazon.com/bedrock/" target="_blank">Bedrock Console</a> and use it directly - no need for AWS Access Keys.
                </div>

                <h3>Setup</h3>
                <ol>
                    <li>Go to <a href="https://console.aws.amazon.com/bedrock/" target="_blank">AWS Bedrock Console</a></li>
                    <li>Navigate to <strong>API keys</strong> ‚Üí <strong>Generate API key</strong></li>
                    <li>Choose <strong>Long-term</strong> (for production) or <strong>Short-term</strong> (for testing)</li>
                    <li>Copy the generated API key</li>
                </ol>

                <h3>Python Example</h3>
                <pre><code class="language-python">import requests

APIFY_TOKEN = "your_apify_token"
BEDROCK_API_KEY = "your_bedrock_api_key"

response = requests.post(
    "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/run-sync-get-dataset-items",
    params={"token": APIFY_TOKEN},
    json={
        "mode": "api",
        "companies": [
            {"companyName": "Grab", "website": "https://grab.com", "location": "Singapore"},
            {"companyName": "Gojek", "website": "https://gojek.com", "location": "Jakarta"}
        ],
        "enrichment": {
            "sources": ["google_maps", "website"]
        },
        "llm": {
            "enabled": True,
            "provider": "bedrock",
            "apiKey": BEDROCK_API_KEY,
            "region": "us-east-1",
            "model": "us.anthropic.claude-haiku-4-5-20251001-v1:0"
        },
        "scoring": {
            "enabled": True,
            "icpCriteria": "Southeast Asian tech companies with Series B+ funding"
        }
    },
    timeout=300
)

results = response.json()
for company in results:
    print(f"{company['companyName']}: Lead Score {company['leadScore']}/100")</code></pre>

                <div class="warning-box">
                    <strong>‚ö†Ô∏è Important:</strong> Use <strong>inference profile IDs</strong> (e.g., <code>us.anthropic.claude-haiku-4-5-20251001-v1:0</code>), not direct model IDs. The <code>us.</code> prefix is required for us-east-1 region.
                </div>

                <h3>Available Models</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Model</th>
                            <th>Inference Profile ID (us-east-1)</th>
                            <th>Cost/Lead</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Claude Haiku 4.5</td>
                            <td><code>us.anthropic.claude-haiku-4-5-20251001-v1:0</code></td>
                            <td>~$0.0004</td>
                        </tr>
                        <tr>
                            <td>Claude Sonnet 4.5</td>
                            <td><code>us.anthropic.claude-sonnet-4-5-20250929-v1:0</code></td>
                            <td>~$0.002</td>
                        </tr>
                        <tr>
                            <td>Claude Opus 4.5</td>
                            <td><code>us.anthropic.claude-opus-4-5-20251101-v1:0</code></td>
                            <td>~$0.015</td>
                        </tr>
                    </tbody>
                </table>

                <h2 id="output-schema">Output Schema</h2>
                <p>The API returns an array of enrichment results with metadata. Here's the complete response structure:</p>

                <h3>Response Format</h3>
                <pre><code class="language-json">[
  {
    "type": "RUN_STATS",
    "timestamp": "2025-12-21T10:44:04.480Z",
    "mode": "api",
    "stats": {
      "companiesProcessed": 3,
      "enrichmentSuccessful": 3,
      "enrichmentFailed": 0,
      "sources": ["google_maps", "website", "hunter"],
      "llmEnabled": true
    }
  },
  {
    "type": "ENRICHED_COMPANY",
    "input": {
      "companyName": "Acme Corp",
      "website": "https://www.acmecorp.example",
      "location": "San Francisco, CA"
    },
    "output": {
      "email": "contact@acmecorp.example",
      "phone": "+1-555-0123",
      "linkedinUrl": "https://www.linkedin.com/company/acmecorp",
      "facebookUrl": "https://www.facebook.com/acmecorp",
      "twitterHandle": "@acmecorp",
      "dataConfidence": 0.85,
      "industry": "Enterprise Software",
      "description": "Acme Corp is a leading enterprise software provider specializing in cloud-based solutions for modern businesses.",
      "techStack": ["React", "Node.js", "PostgreSQL", "AWS"],
      "enrichedAt": "2025-12-21T10:43:57.293Z",
      "enrichmentSources": ["website", "hunter"],
      "processingTime": 1231,
      "leadScore": 88,
      "icpScore": 38,
      "icpReasoning": "Acme Corp is an exceptional ICP match as an enterprise software company with proven Series B+ funding, strong technology stack alignment, and demonstrated need for scalable cloud infrastructure. Their multi-region deployment requirements and compliance needs align perfectly with organizations seeking robust, enterprise-grade solutions.",
      "summary": "Acme Corp is a rapidly growing enterprise software platform serving Fortune 500 customers across multiple industries. The company has secured significant venture funding and operates a sophisticated cloud infrastructure supporting millions of daily transactions. Their technology-forward approach and expansion into new markets demonstrate strong alignment with solutions requiring scalable, compliant infrastructure."
    },
    "success": true
  }
]</code></pre>

                <div class="info-box" style="margin-top: 20px;">
                    <strong>üí° Response Structure:</strong> The API returns both run statistics and individual enriched company records. Each company includes comprehensive contact data, business intelligence, and AI-generated insights (ICP reasoning, summary) tailored to your specific criteria.
                </div>

                <h2 id="webhook">Webhook Integration</h2>
                <p>Receive enrichment results via webhook for event-driven architectures:</p>

                <h3>Configure Webhook</h3>
                <pre><code class="language-json">{
  "mode": "api",
  "companies": [...],
  "webhookUrl": "https://your-system.com/webhook"
}</code></pre>

                <h3>Webhook Payload</h3>
                <p>When the enrichment completes, you'll receive:</p>

                <pre><code class="language-json">{
  "type": "RUN_COMPLETED",
  "runId": "abc123",
  "datasetId": "xyz789",
  "timestamp": "2025-12-19T14:35:00Z",
  "stats": {
    "totalCompanies": 50,
    "successful": 47,
    "failed": 3,
    "avgLeadScore": 72.4,
    "avgDataConfidence": 0.81
  },
  "results": [...]
}</code></pre>

                <h2 id="lambda">AWS Lambda Integration</h2>
                <p>Enrich leads from S3 using AWS Lambda functions:</p>

                <pre><code class="language-python">import boto3
import requests
import json
import os

s3 = boto3.client('s3')
APIFY_TOKEN = os.environ['APIFY_TOKEN']

def lambda_handler(event, context):
    # Read companies from S3
    obj = s3.get_object(Bucket='my-bucket', Key='leads/pending.json')
    companies = json.loads(obj['Body'].read())

    # Enrich via Apify (max 100 per run)
    batches = [companies[i:i+100] for i in range(0, len(companies), 100)]
    all_results = []

    for batch in batches:
        run = requests.post(
            "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/run-sync-get-dataset-items",
            params={"token": APIFY_TOKEN},
            json={
                "mode": "api",
                "companies": batch,
                "enrichment": {"sources": ["google_maps", "website"]}
            }
        ).json()
        all_results.extend(run)

    # Write enriched data back to S3
    s3.put_object(
        Bucket='my-bucket',
        Key='leads/enriched.json',
        Body=json.dumps(all_results)
    )

    return {"enriched": len(all_results)}</code></pre>

                <h2 id="airflow">Apache Airflow DAG</h2>
                <p>Schedule and orchestrate lead enrichment with Apache Airflow:</p>

                <pre><code class="language-python">from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import requests

default_args = {
    'owner': 'data-team',
    'retries': 2
}

def enrich_leads(**context):
    """Call Apify actor to enrich leads."""
    ti = context['ti']
    leads = ti.xcom_pull(task_ids='extract_leads')

    response = requests.post(
        "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/run-sync-get-dataset-items",
        params={"token": Variable.get("APIFY_TOKEN")},
        json={
            "mode": "api",
            "companies": leads,
            "enrichment": {"sources": ["google_maps", "website"]},
            "llm": {
                "enabled": True,
                "provider": "openai",
                "apiKey": Variable.get("OPENAI_API_KEY")
            }
        },
        timeout=300
    )

    return response.json()

with DAG(
    'lead_enrichment_pipeline',
    default_args=default_args,
    schedule_interval='0 2 * * *',  # Daily at 2 AM
    start_date=datetime(2025, 1, 1),
    catchup=False
) as dag:

    extract = PythonOperator(
        task_id='extract_leads',
        python_callable=extract_leads
    )

    enrich = PythonOperator(
        task_id='enrich_leads',
        python_callable=enrich_leads
    )

    load = PythonOperator(
        task_id='load_to_warehouse',
        python_callable=load_to_warehouse
    )

    extract >> enrich >> load</code></pre>

                <h2 id="glue">AWS Glue Integration</h2>
                <p>Use AWS Glue ETL jobs to enrich data from your data catalog:</p>

                <pre><code class="language-python">import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
import requests
import json

args = getResolvedOptions(sys.argv, ['JOB_NAME', 'APIFY_TOKEN'])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

# Read leads from S3
datasource = glueContext.create_dynamic_frame.from_catalog(
    database="leads_db",
    table_name="raw_leads"
)

# Convert to list of companies
companies = []
for record in datasource.toDF().collect():
    companies.append({
        "companyName": record.company_name,
        "website": record.website
    })

# Enrich in batches (max 100 per run)
enriched_results = []
for i in range(0, len(companies), 100):
    batch = companies[i:i+100]

    response = requests.post(
        "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/run-sync-get-dataset-items",
        params={"token": args['APIFY_TOKEN']},
        json={
            "mode": "api",
            "companies": batch,
            "enrichment": {"sources": ["google_maps", "website"]}
        },
        timeout=300
    )
    enriched_results.extend(response.json())

# Write enriched data back to S3
df = spark.createDataFrame(enriched_results)
glueContext.write_dynamic_frame.from_options(
    frame=DynamicFrame.fromDF(df, glueContext, "enriched"),
    connection_type="s3",
    connection_options={"path": "s3://my-bucket/enriched-leads/"},
    format="parquet"
)

job.commit()</code></pre>

                <div class="info-box">
                    <strong>Tip:</strong> Use Glue job parameters to securely pass APIFY_TOKEN instead of hardcoding.
                </div>

                <h2 id="gcp">Google Cloud Functions</h2>
                <p>Deploy serverless enrichment functions on Google Cloud Platform:</p>

                <pre><code class="language-python">import functions_framework
from google.cloud import storage
import requests
import json
import os

@functions_framework.http
def enrich_leads(request):
    """HTTP Cloud Function to enrich leads from Cloud Storage."""

    storage_client = storage.Client()
    bucket = storage_client.bucket('my-leads-bucket')

    # Read pending leads
    blob = bucket.blob('leads/pending.json')
    companies = json.loads(blob.download_as_text())

    # Enrich via Apify
    enriched = []
    for i in range(0, len(companies), 100):
        batch = companies[i:i+100]

        response = requests.post(
            "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/run-sync-get-dataset-items",
            params={"token": os.environ['APIFY_TOKEN']},
            json={
                "mode": "api",
                "companies": batch,
                "enrichment": {"sources": ["google_maps", "website"]},
                "llm": {
                    "enabled": True,
                    "provider": "openai",
                    "apiKey": os.environ['OPENAI_API_KEY']
                }
            },
            timeout=300
        )
        enriched.extend(response.json())

    # Write enriched data
    output_blob = bucket.blob('leads/enriched.json')
    output_blob.upload_from_string(
        json.dumps(enriched, indent=2),
        content_type='application/json'
    )

    return {
        "success": True,
        "enriched": len(enriched),
        "output": "gs://my-leads-bucket/leads/enriched.json"
    }</code></pre>

                <h3>Deploy</h3>
                <pre><code class="language-bash">gcloud functions deploy enrich-leads \
  --runtime python39 \
  --trigger-http \
  --allow-unauthenticated \
  --set-env-vars APIFY_TOKEN=your_token,OPENAI_API_KEY=your_key \
  --timeout 540s \
  --memory 512MB</code></pre>

                <h2 id="step-functions">AWS Step Functions (Durable Lambda)</h2>
                <p>For long-running enrichment jobs that exceed Lambda's 15-minute limit:</p>

                <h3>Step Functions State Machine</h3>
                <pre><code class="language-json">{
  "Comment": "Lead Enrichment Pipeline",
  "StartAt": "ReadLeads",
  "States": {
    "ReadLeads": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:read-leads-from-s3",
      "Next": "EnrichLeads"
    },
    "EnrichLeads": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:enrich-via-apify",
      "Retry": [
        {
          "ErrorEquals": ["States.TaskFailed"],
          "IntervalSeconds": 30,
          "MaxAttempts": 3,
          "BackoffRate": 2.0
        }
      ],
      "Next": "WriteResults"
    },
    "WriteResults": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:write-to-s3",
      "End": true
    }
  }
}</code></pre>

                <h3>Enrich Lambda Function</h3>
                <pre><code class="language-python">import boto3
import requests
import os

def lambda_handler(event, context):
    """Long-running enrichment via Step Functions."""
    companies = event['companies']

    # Start async Apify run
    run = requests.post(
        "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/runs",
        params={"token": os.environ['APIFY_TOKEN']},
        json={
            "mode": "api",
            "companies": companies,
            "enrichment": {"sources": ["google_maps", "website", "hunter"]},
            "llm": {"enabled": True, "provider": "openai", "apiKey": os.environ['OPENAI_KEY']}
        }
    ).json()

    run_id = run['data']['id']

    # Poll for completion (Step Functions handles timeout)
    while True:
        status = requests.get(
            f"https://api.apify.com/v2/actor-runs/{run_id}",
            params={"token": os.environ['APIFY_TOKEN']}
        ).json()

        if status['data']['status'] in ['SUCCEEDED', 'FAILED']:
            break

    # Get results
    dataset_id = status['data']['defaultDatasetId']
    results = requests.get(
        f"https://api.apify.com/v2/datasets/{dataset_id}/items",
        params={"token": os.environ['APIFY_TOKEN']}
    ).json()

    return {"enrichedLeads": results, "count": len(results)}</code></pre>

                <h2 id="snowflake">Snowflake Integration</h2>
                <p>Enrich leads directly from Snowflake tables using Python stored procedures:</p>

                <pre><code class="language-sql">-- Create stored procedure
CREATE OR REPLACE PROCEDURE enrich_leads()
RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.8'
PACKAGES = ('snowflake-snowpark-python', 'requests')
HANDLER = 'enrich_leads_handler'
AS
$$
import requests
import json

def enrich_leads_handler(session):
    # Read pending leads from table
    leads_df = session.table("RAW_LEADS").filter("ENRICHED_AT IS NULL").limit(100)
    companies = []

    for row in leads_df.collect():
        companies.append({
            "companyName": row.COMPANY_NAME,
            "website": row.WEBSITE
        })

    # Enrich via Apify
    response = requests.post(
        "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/run-sync-get-dataset-items",
        params={"token": "YOUR_APIFY_TOKEN"},
        json={
            "mode": "api",
            "companies": companies,
            "enrichment": {"sources": ["google_maps", "website"]}
        },
        timeout=300
    )

    enriched = response.json()

    # Insert enriched data
    for lead in enriched:
        session.sql(f"""
            UPDATE RAW_LEADS
            SET EMAIL = '{lead.get('email', '')}',
                PHONE = '{lead.get('phone', '')}',
                RATING = {lead.get('rating', 0)},
                LEAD_SCORE = {lead.get('leadScore', 0)},
                ENRICHED_AT = CURRENT_TIMESTAMP()
            WHERE COMPANY_NAME = '{lead['companyName']}'
        """).collect()

    return f"Enriched {len(enriched)} leads"
$$;

-- Schedule with task
CREATE OR REPLACE TASK enrich_leads_daily
  WAREHOUSE = COMPUTE_WH
  SCHEDULE = 'USING CRON 0 2 * * * UTC'
AS
  CALL enrich_leads();

ALTER TASK enrich_leads_daily RESUME;</code></pre>

                <h2 id="redshift">Amazon Redshift Integration</h2>
                <p>Enrich leads from Redshift using Lambda + S3 unload:</p>

                <h3>Step 1: Unload to S3</h3>
                <pre><code class="language-sql">-- Unload pending leads to S3
UNLOAD (
  'SELECT company_name, website
   FROM leads
   WHERE enriched_at IS NULL
   LIMIT 1000'
)
TO 's3://my-bucket/leads/pending_'
IAM_ROLE 'arn:aws:iam::123456789012:role/RedshiftS3Role'
FORMAT AS JSON
PARALLEL OFF;</code></pre>

                <h3>Step 2: Lambda Enrichment</h3>
                <pre><code class="language-python">import boto3
import requests
import json
import psycopg2

def lambda_handler(event, context):
    s3 = boto3.client('s3')

    # Read from S3
    obj = s3.get_object(Bucket='my-bucket', Key='leads/pending_0000')
    companies = [json.loads(line) for line in obj['Body'].read().decode().splitlines()]

    # Enrich
    response = requests.post(
        "https://api.apify.com/v2/acts/datahq~airtable-lead-enricher/run-sync-get-dataset-items",
        params={"token": os.environ['APIFY_TOKEN']},
        json={"mode": "api", "companies": companies},
        timeout=300
    )
    enriched = response.json()

    # Write back to S3
    s3.put_object(
        Bucket='my-bucket',
        Key='leads/enriched.json',
        Body=json.dumps(enriched)
    )

    # Copy to Redshift
    conn = psycopg2.connect(
        host=os.environ['REDSHIFT_HOST'],
        port=5439,
        dbname='analytics',
        user=os.environ['REDSHIFT_USER'],
        password=os.environ['REDSHIFT_PASSWORD']
    )

    with conn.cursor() as cur:
        cur.execute(f"""
            COPY enriched_leads
            FROM 's3://my-bucket/leads/enriched.json'
            IAM_ROLE 'arn:aws:iam::123456789012:role/RedshiftS3Role'
            FORMAT AS JSON 'auto';
        """)
        conn.commit()

    return {"enriched": len(enriched)}</code></pre>

                <h2 id="data-lake">Data Lake Pattern (S3)</h2>
                <p>Write enriched data to partitioned data lakes for analytics:</p>

                <pre><code class="language-python"># Write enriched data to partitioned data lake
from datetime import datetime

partition_path = f"s3://datalake/enriched-leads/year={datetime.now().year}/month={datetime.now().month:02d}/"

s3.put_object(
    Bucket='datalake',
    Key=f"{partition_path}leads_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet",
    Body=df.to_parquet()
)</code></pre>

                <h2 id="rate-limits">Rate Limits & Batching</h2>
                <p>Understanding limits and how to handle large-scale enrichment:</p>

                <table>
                    <thead>
                        <tr>
                            <th>Limit</th>
                            <th>Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Companies/run</td>
                            <td>100</td>
                        </tr>
                        <tr>
                            <td>Concurrent runs</td>
                            <td>10</td>
                        </tr>
                        <tr>
                            <td>Run timeout</td>
                            <td>1 hour</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Batch Processing (1000+ leads)</h3>
                <pre><code class="language-python">import asyncio
import aiohttp

async def enrich_all(companies, token):
    """Enrich all companies with controlled concurrency."""
    batches = [companies[i:i+100] for i in range(0, len(companies), 100)]

    async with aiohttp.ClientSession() as session:
        tasks = [enrich_batch(session, batch, token) for batch in batches]
        results = await asyncio.gather(*tasks)

    return [item for batch_results in results for item in batch_results]</code></pre>

                <h2 id="cost-estimation">Cost Estimation</h2>
                <p>Estimated costs for different batch sizes:</p>

                <table>
                    <thead>
                        <tr>
                            <th>Companies</th>
                            <th>Apify Cost</th>
                            <th>LLM Cost</th>
                            <th>Total</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>100</td>
                            <td>$3.00</td>
                            <td>$0.10</td>
                            <td>$3.10</td>
                        </tr>
                        <tr>
                            <td>1,000</td>
                            <td>$30.00</td>
                            <td>$1.00</td>
                            <td>$31.00</td>
                        </tr>
                        <tr>
                            <td>10,000</td>
                            <td>$300.00</td>
                            <td>$10.00</td>
                            <td>$310.00</td>
                        </tr>
                    </tbody>
                </table>

                <div class="info-box">
                    <strong>Note:</strong> LLM costs based on GPT-4o-mini (~$0.001/lead). Hunter.io costs separate if enabled.
                </div>

                <hr style="margin: 40px 0; border: none; border-top: 1px solid #ddd;">

                <p style="text-align: center; color: #666; font-size: 0.9em;">
                    <a href="index.html">Documentation</a> ‚Ä¢
                    <a href="extension.html">Extension Guide</a> ‚Ä¢
                    <a href="terms.html">Terms</a> ‚Ä¢
                    <a href="privacy.html">Privacy</a>
                </p>
            </div>
        </main>
    </div>
</body>
</html>
